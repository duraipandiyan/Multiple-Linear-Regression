{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631aa012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YearsExperience    Salary\n",
      "0               1.1   39343.0\n",
      "1               1.3   46205.0\n",
      "2               1.5   37731.0\n",
      "3               2.0   43525.0\n",
      "4               2.2   39891.0\n",
      "5               2.9   56642.0\n",
      "6               3.0   60150.0\n",
      "7               3.2   54445.0\n",
      "8               3.2   64445.0\n",
      "9               3.7   57189.0\n",
      "10              3.9   63218.0\n",
      "11              4.0   55794.0\n",
      "12              4.0   56957.0\n",
      "13              4.1   57081.0\n",
      "14              4.5   61111.0\n",
      "15              4.9   67938.0\n",
      "16              5.1   66029.0\n",
      "17              5.3   83088.0\n",
      "18              5.9   81363.0\n",
      "19              6.0   93940.0\n",
      "20              6.8   91738.0\n",
      "21              7.1   98273.0\n",
      "22              7.9  101302.0\n",
      "23              8.2  113812.0\n",
      "24              8.7  109431.0\n",
      "25              9.0  105582.0\n",
      "26              9.5  116969.0\n",
      "27              9.6  112635.0\n",
      "28             10.3  122391.0\n",
      "29             10.5  121872.0\n"
     ]
    }
   ],
   "source": [
    " # pandas is a library which help us to malipulate the datas like TABLE structures \n",
    "import pandas as pd\n",
    "\n",
    "# read the data from CSV file using inbult method form Pandas\n",
    "Data_set=pd.read_csv('Salary_Data.csv') \n",
    "print(Data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd7ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seprate the INPUT(X_DATA) and OUTPUT(Y_DATA) from CSV file\n",
    "Indipendant=Data_set[['YearsExperience']]\n",
    "Dependent=Data_set[['Salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecca256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YearsExperience\n",
      "22              7.9\n",
      "5               2.9\n",
      "16              5.1\n",
      "8               3.2\n",
      "14              4.5\n",
      "23              8.2\n",
      "20              6.8\n",
      "1               1.3\n",
      "29             10.5\n",
      "6               3.0\n",
      "4               2.2\n",
      "18              5.9\n",
      "19              6.0\n",
      "9               3.7\n",
      "7               3.2\n",
      "25              9.0\n",
      "3               2.0\n",
      "0               1.1\n",
      "21              7.1\n",
      "15              4.9\n",
      "12              4.0       Salary\n",
      "22  101302.0\n",
      "5    56642.0\n",
      "16   66029.0\n",
      "8    64445.0\n",
      "14   61111.0\n",
      "23  113812.0\n",
      "20   91738.0\n",
      "1    46205.0\n",
      "29  121872.0\n",
      "6    60150.0\n",
      "4    39891.0\n",
      "18   81363.0\n",
      "19   93940.0\n",
      "9    57189.0\n",
      "7    54445.0\n",
      "25  105582.0\n",
      "3    43525.0\n",
      "0    39343.0\n",
      "21   98273.0\n",
      "15   67938.0\n",
      "12   56957.0\n"
     ]
    }
   ],
   "source": [
    "# Split the TRAIN and TEST DATA\n",
    "# To split train_test we must import the library sklearn which is inbult method train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(Indipendant, Dependent, test_size=0.30, random_state=0) # We stored 4 different variavle for Train and test\n",
    "\n",
    "print(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f122fff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9360.26128619]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we should Train the Model \n",
    "# import the sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "Regressor=LinearRegression()\n",
    "Regressor.fit(X_train,Y_train) # We just train the X and Y values\n",
    "\n",
    "Regressor.coef_ # Weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a376dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26777.3913412])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Regressor.intercept_ # Bais or origin value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d6c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the value using Test data\n",
    "Predict_data=Regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d89b041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740993407213511"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have predicted but we should check the whether the model is eficent or not\n",
    "\n",
    "from sklearn.metrics import r2_score # to find the R^2 value we must  import r2_score\n",
    "r2_score(Y_test,Predict_data) #find the R^2 value if it is close to 1 which is good model or else bad model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "429acb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should save the file as a binary - which helps us to hide our code\n",
    "# In order to save we must use Pickle model which is inbult meethod in python \n",
    "\n",
    "import pickle as pk # pickle is the process to serialisation and deserialisation \n",
    "file_name='Save_project.sav' # .sav syntex to save the project\n",
    "pk.dump(Regressor,open(file_name,'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f31d608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Please Enter your year: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\durai\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[148460.78806172]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years=int(input(\" Please Enter your year: \"))\n",
    "salary_predict=pk.load(open(file_name,'rb')) # Now we have deserialisation our project \n",
    "salary_predict.predict([[years]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c82b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
